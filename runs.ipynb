{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from network import GCNet, DeeperGCN\n",
    "from train import train_model, plot_results\n",
    "from data2 import get_sdf_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_objects, batch_size, n_epoch = 100, 1, 200\n",
    "in_channels, out_channels = 3, 1\n",
    "hidden_channels = [128, 128, 128, 128, 128]\n",
    "loss_func = nn.L1Loss()\n",
    "edge_weight = True\n",
    "step_size, gamma = 60, 0.5\n",
    "lr_0 = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data2/dataset_1/graph1/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data2/dataset_1/graph2/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data2/dataset_1/graph3/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data2/dataset_1/graph4/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing sdf data loader\n",
      "training begins\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 2.82 GiB already allocated; 4.20 MiB free; 2.84 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5c6115b7451a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# model = GCNet(in_channels, hidden_channels, out_channels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeeperGCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - ANSYS, Inc\\Projects\\sdf-prediction-graph\\train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_data, lr_0, n_epoch, loss_func, with_eikonal_loss, print_every, step_size, gamma, radius)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m#loss = loss_func(pred, target)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - ANSYS, Inc\\Projects\\sdf-prediction-graph\\network.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, dat)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0medge_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\conv\\gen_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;31m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg_norm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mmsg_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minspector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoll_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[1;31m# For `GNNExplainer`, we require a separate message and aggregate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\conv\\gen_conv.py\u001b[0m in \u001b[0;36mmessage\u001b[1;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_j\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0medge_attr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx_j\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 2.82 GiB already allocated; 4.20 MiB free; 2.84 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "step_size, gamma, n_epoch = 150, 0.6, 500\n",
    "edge_weight = False\n",
    "radius = 0.1\n",
    "batch_size = 1\n",
    "data_folder = \"data2/dataset_1/graph11/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "# model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "model = DeeperGCN(3, 8, 1, 1, 1)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma, radius=radius)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size, gamma, n_epoch = 150, 0.6, 500\n",
    "edge_weight = False\n",
    "radius = 0.1\n",
    "batch_size = 5\n",
    "data_folder = \"data2/dataset_1/graph11/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma, radius=radius)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size, gamma, n_epoch = 150, 0.5, 200\n",
    "radius = 0.1\n",
    "batch_size = 5\n",
    "data_folder = \"data2/dataset_1/graph5/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma, radius=radius)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size, gamma, n_epoch = 150, 0.5, 600\n",
    "data_folder = \"data2/dataset_1/graph6/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data2/dataset_1/graph7/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data2/dataset_1/graph8/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data2/dataset_1/graph9/\"\n",
    "train_data = get_sdf_data_loader(n_objects, data_folder, batch_size, edge_weight=edge_weight)\n",
    "model = GCNet(in_channels, hidden_channels, out_channels)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma)\n",
    "plot_results(model, train_data, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_sdf_data_loader2(n_objects, data_folder, batch_size, edge_weight=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sdf_data_loader2(n_objects, data_folder, batch_size, reversed_edge_already_included=False, edge_weight=False):\n",
    "    graph_data_list = []\n",
    "    print(\"preparing sdf data loader\")\n",
    "    for i in range(n_objects):\n",
    "        graph_nodes = np.load(data_folder + \"graph_nodes%d.npy\" % i).astype(float)\n",
    "        x = graph_nodes.copy()\n",
    "        x[:, 2] = (x[:, 2] < 0).astype(float)\n",
    "        x[:, 5] = (x[:, 5] < 0).astype(float)\n",
    "        y = graph_nodes.copy()[:, [2, 5]]\n",
    "        graph_cells = np.load(data_folder + \"graph_cells%d.npy\" % i).astype(int)\n",
    "        graph_cells = graph_cells.T\n",
    "        graph_edges = np.load(data_folder + \"graph_edges%d.npy\" % i).astype(int)\n",
    "        if not reversed_edge_already_included:\n",
    "            graph_edges = add_reversed_edges(graph_edges)\n",
    "        graph_edges = graph_edges.T\n",
    "        n_edges = graph_edges.shape[1]\n",
    "        if edge_weight:\n",
    "            graph_edge_weights = np.load(data_folder + \"graph_weights%d.npy\" %i).astype(float)\n",
    "            if graph_edge_weights.shape[0] == n_edges:\n",
    "                pass\n",
    "            elif graph_edge_weights.shape[0] == n_edges // 2:\n",
    "                graph_edge_weights = np.concatenate([graph_edge_weights, graph_edge_weights])\n",
    "            else:\n",
    "                raise(\"edge weight size is wrong.\")\n",
    "            #graph_edge_weights = graph_edge_weights.reshape(-1, 1)\n",
    "        else:\n",
    "            graph_edge_weights = np.ones(n_edges)\n",
    "\n",
    "        graph_data = Data(x=torch.from_numpy(x).type(torch.float32),\n",
    "                          y=torch.from_numpy(y).type(torch.float32),\n",
    "                          edge_index=torch.from_numpy(graph_edges).type(torch.long),\n",
    "                          edge_attr=torch.from_numpy(graph_edge_weights).type(torch.float32),\n",
    "                          face=torch.from_numpy(graph_cells).type(torch.long))\n",
    "        graph_data_list.append(graph_data)\n",
    "    train_data = DataLoader(graph_data_list, batch_size=batch_size)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "graph_nodes1 = np.load(\"data2/dataset_1/graph1/graph_nodes%d.npy\" % i).astype(float)\n",
    "graph_nodes2 = np.load(\"data2/dataset_1/graph10/graph_nodes%d.npy\" % i).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nodes1.shape, graph_nodes2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(graph_nodes1[:, 0], graph_nodes1[:, 1], 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data2/dataset_1/graph10/\"\n",
    "train_data = get_sdf_data_loader2(n_objects, data_folder, batch_size, edge_weight=False)\n",
    "model = GCNet(6, hidden_channels, 2)\n",
    "train_model(model, train_data, lr_0=lr_0, n_epoch=n_epoch, loss_func=loss_func, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results2(model, data):\n",
    "    \n",
    "    loss_history = np.load(\"models/loss.npy\")\n",
    "    plt.plot(loss_history)\n",
    "    plt.yscale('log')\n",
    "\n",
    "    device = 'cpu'\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(\"models/model\" + \".pth\", map_location=device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, d in enumerate(data):\n",
    "            d = d.to(device=device)\n",
    "            pred = model(d)\n",
    "            cells = d.face.numpy()\n",
    "            points = d.x.numpy()[:, :3]\n",
    "            points[:, 2] = 0.\n",
    "            mesh = meshio.Mesh(points=points, cells=[(\"triangle\", cells.T)])\n",
    "            plt.figure(figsize=(12, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plot_mesh(mesh, vals=pred.numpy()[:, 0])\n",
    "            plt.colorbar()\n",
    "            plt.gca().set_xticks([])\n",
    "            plt.gca().set_yticks([])\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plot_mesh(mesh, vals=d.y.numpy()[:, 0])\n",
    "            plt.colorbar()\n",
    "            plt.gca().set_xticks([])\n",
    "            plt.gca().set_yticks([])\n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results2(model, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh_to_pixel_training(model, train_data, labels):\n",
    "    print(\"training begins\")\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_0, weight_decay=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    running_loss_list = []\n",
    "    for epoch in range(1, n_epoch):\n",
    "        running_loss = 0\n",
    "        for d, l in zip(train_data, labels):\n",
    "            d = d.to(device)\n",
    "            if with_eikonal_loss:\n",
    "                d.x.requires_grad = True\n",
    "                #Todo: make sure d.x does not participate in optimization.\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(d)\n",
    "            target = l\n",
    "            loss = loss_func(pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        if epoch % print_every == 0:\n",
    "            print(\"epoch=%d, loss=%0.5e, lr=%0.5e\" % (epoch, running_loss / len(train_data),\n",
    "                                                      optimizer.param_groups[0]['lr']))\n",
    "        running_loss_list.append(running_loss / len(train_data))\n",
    "\n",
    "    torch.save(model.state_dict(), \"models/model\" + \".pth\")\n",
    "    np.save(\"models/loss.npy\", running_loss_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data2 import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "geometries = [\"Rectangle\"]\n",
    "n_objects = 100\n",
    "\n",
    "root_folder = \"data2/dataset_4/\"\n",
    "mesh_folder = root_folder + \"mesh/\"\n",
    "mesh_coarse_size, mesh_fine_size, skip_every, refined = 0.1, 0.025, 2, True\n",
    "mesh_data = MeshData(geometries, mesh_coarse_size, mesh_fine_size, refined, skip_every)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_data.write_mesh_features_to_file(mesh_folder)\n",
    "for i in range(n_objects):\n",
    "    plot = True if i % 10 == 0 else False\n",
    "    mesh_data.generate_sdf_mesh(mesh_folder, name=str(i), plot=plot, save_sdf_pxl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_folder = root_folder + \"graph1/\"\n",
    "graph_data = GraphData(graph_node=\"vertex\", graph_edge=\"edge\", edge_length=1, edge_weight=\"length\")\n",
    "graph_data.generate_graph_data(n_objects, mesh_folder, graph_folder=graph_folder)\n",
    "graph_data.write_graph_features_to_file(graph_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader as DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(n_objects):\n",
    "    sdf_pxl_file = mesh_folder + \"sdf_pxl\" + str(i) + \".npy\"\n",
    "    sdf_pxl = np.load(sdf_pxl_file)\n",
    "    labels.append(sdf_pxl)\n",
    "labels = DL(labels, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels:\n",
    "    print(i)\n",
    "    print(i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNet_mixed(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_gcnn_channels, hidden_cnn_channels, out_channels, act=F.relu):\n",
    "        super(GCNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_gcnn_channels = hidden_gcnn_channels\n",
    "        self.hidden_cnn_channel = hidden_cnn_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.act = act\n",
    "\n",
    "        self.gconvs = torch.nn.ModuleList()\n",
    "        self.gconvs.append(GCNConv(in_channels, hidden_gcnn_channels[0], improved=True))\n",
    "        for i in range(len(hidden_gcnn_channels) - 1):\n",
    "            self.gconvs.append(GCNConv(hidden_gcnn_channels[i], hidden_gcnn_channels[i+1], improved=True))\n",
    "        self.gconvs.append(GCNConv(hidden_gcnn_channels[-1], hidden_cnn_channels, improved=True))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for i in range(len(hidden_cnn_channels) - 1):\n",
    "            self.convs.append(Conv(hidden_cnn_channels[i], hidden_cnn_channels[i+1]))\n",
    "        self.convs.append(Conv(hidden_cnn_channels[-1], out_channels))\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for gconv in self.gconvs:\n",
    "            gconv.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\"\"\"\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        #edge_weight = x.new_ones(edge_index.size(1))\n",
    "        edge_weight = data.edge_attr\n",
    "\n",
    "        for i in range(len(self.convs) - 1):\n",
    "            #edge_index, edge_weight = self.augment_adj(edge_index, edge_weight, x.size(0))\n",
    "            x = self.convs[i](x, edge_index, edge_weight)\n",
    "            x = self.act(x)\n",
    "\n",
    "        #edge_index, edge_weight = self.augment_adj(edge_index, edge_weight, x.size(0))\n",
    "        x = self.convs[-1](x, edge_index, edge_weight)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def augment_adj(self, edge_index, edge_weight, num_nodes):\n",
    "        edge_index, edge_weight = add_self_loops(edge_index, edge_weight,\n",
    "                                                 num_nodes=num_nodes)\n",
    "        edge_index, edge_weight = sort_edge_index(edge_index, edge_weight,\n",
    "                                                  num_nodes)\n",
    "        edge_index, edge_weight = spspmm(edge_index, edge_weight, edge_index,\n",
    "                                         edge_weight, num_nodes, num_nodes,\n",
    "                                         num_nodes)\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, {}, depth={}, pool_ratios={})'.format(\n",
    "            self.__class__.__name__, self.in_channels, self.hidden_channels,\n",
    "            self.out_channels, self.depth, self.pool_ratios)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
